{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOpNH-BqqW5m"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtmrn6lD--kF"
   },
   "source": [
    "**Question 0 (-2 pts if not provided):**  Enter your name and SU ID in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bizycRXz_uM6"
   },
   "source": [
    "Your name and SU ID Here: Yunhan Zhang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "b-ZUbX3nqW5q",
    "nbgrader": {
     "checksum": "c51f80b694da894627ba37be28c86055",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professors: \n",
    "  - Willard Williamson <wewillia@syr.edu>\n",
    "  - Emory Creel <emcreel@syr.edu>\n",
    "- Faculty Assistant: Shubham Sharma <shsharma@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n",
    "- Google Colab is the official class runtime environment so you should test your code on Colab before submission.\n",
    "- Do not modify cells marked as grading cells or marked as do not modify.\n",
    "- Before submitting your work, remember to check for run time errors with the following procedure:\n",
    "`Runtime `$\\rightarrow$ Factory reset runtime followed by Runtime $\\rightarrow$ Run All.  All runtime errors will result in a minimum penalty of half off.\n",
    "- All plots shall include descriptive title and axis labels.  Plot legends shall be included where possible.  Unless stated otherwise, plots can be made using any Python plotting package.  It is understood that spark data structures must be converted to something like numpy or pandas prior to making plots.  All required mathematical operations, filtering, selection, etc., required by a homework question shall be performed in spark prior to converting to numpy or pandas.\n",
    "- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n",
    "- Don't add or remove files from your git repo.\n",
    "- Do not change file names in your repo.  This also means don't change the title of the ipython notebook.\n",
    "- You are free to add additional code cells around the cells marked `your code here`.\n",
    "- We reserve the right to take points off for operations that are extremely inefficient or \"heavy weight\".  This is a big data class and extremely inefficient operations make a big difference when scaling up to large data sets.  For example, the spark dataframe collect() method is a very heavy weight operation and should not be used unless it there is a real need for it.  An example where collect() might be needed is to get ready to make a plot after filtering a spark dataframe.\n",
    "- import * is not allowed because it is considered a very bad coding practice and in some cases can result in a significant delay (which slows down the grading process) in loading imports.  For example, the statement `from sympy import *` is not allowed.  You must import the specific packages that you need. \n",
    "- The graders reserve the right to deduct points for subjective things we see with your code.  For example, if we ask you to create a pandas data frame to display values from an investigation and you hard code the values, we will take points off for that.  This is only one of many different things we could find in reviewing your code.  In general, write your code like you are submitting it for a code peer review in industry.  \n",
    "- Level of effort is part of our subjective grading.  For example, in cases where we ask for a more open ended investigation, some students put in significant effort and some students do the minimum possible to meet requirements.  In these cases, we may take points off for students who did not put in much effort as compared to students who put in a lot of effort.  We feel that the students who did a better job deserve a better grade.  We reserve the right to invoke level of effort grading at any time.\n",
    "- Only use spark, spark machine learning, spark data frames, RDD's, and map reduce to solve all problems unless instructed otherwise.\n",
    "- Your notebook must run from start to finish without requiring manual input by the graders.  For example, do not mount your personal Google drive in your notebook as this will require graders to perform manual steps.  In short, your notebook should run from start to finish with no runtime errors and no need for graders to perform any manual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm6l-wPqqW5u"
   },
   "source": [
    "#### Read the data files\n",
    "The cell below reads the assignment data files from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GWwdob0jeo5a"
   },
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'# define an array of data file names\\ndata_file_array=(\"indicator_gapminder_population.csv\" \"indicator_gapminder_under5mortality.csv\" \"indicator_life_expectancy_at_birth.csv\" \"indicator_undata_total_fertility.csv\")\\n\\n# for each data file\\nfor file in ${data_file_array[@]}; do\\n  # if the data file does not exist on the local computer\\n  if [[ ! -f ./${file} ]]; then \\n    # download the data file from github and save it on the local computer\\n    wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/un_indicator_data/${file} &> /dev/null\\n  fi  \\ndone\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m# define an array of data file names\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdata_file_array=(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindicator_gapminder_population.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindicator_gapminder_under5mortality.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindicator_life_expectancy_at_birth.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindicator_undata_total_fertility.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# for each data file\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfor file in $\u001b[39;49m\u001b[38;5;132;43;01m{data_file_array[@]}\u001b[39;49;00m\u001b[38;5;124;43m; do\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  # if the data file does not exist on the local computer\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  if [[ ! -f ./$\u001b[39;49m\u001b[38;5;132;43;01m{file}\u001b[39;49;00m\u001b[38;5;124;43m ]]; then \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # download the data file from github and save it on the local computer\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/un_indicator_data/$\u001b[39;49m\u001b[38;5;132;43;01m{file}\u001b[39;49;00m\u001b[38;5;124;43m &> /dev/null\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  fi  \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdone\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.5/libexec/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.5/libexec/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.5/libexec/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'# define an array of data file names\\ndata_file_array=(\"indicator_gapminder_population.csv\" \"indicator_gapminder_under5mortality.csv\" \"indicator_life_expectancy_at_birth.csv\" \"indicator_undata_total_fertility.csv\")\\n\\n# for each data file\\nfor file in ${data_file_array[@]}; do\\n  # if the data file does not exist on the local computer\\n  if [[ ! -f ./${file} ]]; then \\n    # download the data file from github and save it on the local computer\\n    wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/un_indicator_data/${file} &> /dev/null\\n  fi  \\ndone\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# define an array of data file names\n",
    "data_file_array=(\"indicator_gapminder_population.csv\" \"indicator_gapminder_under5mortality.csv\" \"indicator_life_expectancy_at_birth.csv\" \"indicator_undata_total_fertility.csv\")\n",
    "\n",
    "# for each data file\n",
    "for file in ${data_file_array[@]}; do\n",
    "  # if the data file does not exist on the local computer\n",
    "  if [[ ! -f ./${file} ]]; then \n",
    "    # download the data file from github and save it on the local computer\n",
    "    wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/un_indicator_data/${file} &> /dev/null\n",
    "  fi  \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTcbPHbnqW5w"
   },
   "source": [
    "# Question 1 (10 pts)\n",
    "In the game of [roullete](https://en.wikipedia.org/wiki/Roulette) you can bet on several things including if the ball will land on black or red. In a black or red bet, if you win, you double your earnings. How does the casino make money? If you look at the possibilities you realize that the chance of red or black are both slightly less than 1/2. There are two green spots, so the chance of landing on black (or red) is actually 18/38, or 9/19.<br>\n",
    "Create a utility function which can be used in a monte carlo simulation named get_outcome. The get_outcome function takes as an argument the number of times you play (or spin) the roulette wheel and returns the player's earnings for the number of spins specified.  Assume that the player bets exactly one dollar on black for each spin of the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lqHMxpo6qW5w"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def get_outcome(num_plays):\n",
    "    return (num_plays * 9/19) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MxulRaltqW5x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grading cell - do not change or delete\n",
    "num_plays = 10000\n",
    "get_outcome(num_plays) / num_plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP-jD8W_qW5x"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrpp1gKDqW5y"
   },
   "source": [
    "# Question 2 (10 pts)\n",
    "Using the get_outcome function defined above, use a monte carlo simulation to study the distribution of total earnings.  Run 4 simulations for number of roulette plays = 10, 25, 100, and 1000 where each of the 4 simulations is executed 500 times.  Collect the results into a 2 dimensional numpy array named roulette_sim_array.  Make histogram plots for each of the 4 simulations.  Based on the histogram plots, describe what happens to toal earnings as the number of plays increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SO1Kh8TVqW5y"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSZENtPBqW5z"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIQ95eL-qW50"
   },
   "source": [
    "Your explanation here:<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04DthagfqW50"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tQZjqC4qW50"
   },
   "source": [
    "# Question 3 (10 pts)\n",
    "Using the central limit theorem, create a pandas dataframe named roulette_df containing the sampling distribution of the means from the sample data in the numpy array above.  The pandas dataframe shall have 4 columns labeled with the simulation names. Using data in the roulette_df, plot histograms for each of the sampling distributions - you should have 4 histograms in total.<br>  \n",
    "\n",
    "The following question is based on the theory of central limit theorem sampling.  Assuming you don't know the underlying distribution of the population from which the samples were drawn, some of the histograms are gauranteed to be Gaussian in shape, some are not gauranteed, and some are in a transition region. For each of the 4 simulations, describe if you think the shape is gauranteed to be gaussian, not gauranteed to be Gaussian, or in a transition area between a gaurantee and no gaurantee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbQogU73qW51"
   },
   "outputs": [],
   "source": [
    "# Your histogram code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rYqJ4DvqW51"
   },
   "outputs": [],
   "source": [
    "# Grading cell - do not modify\n",
    "display(roulette_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilgXhOU5qW51"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVJmOUMzqW51"
   },
   "source": [
    "Your explanation here:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXOmG0NDqW52"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV4PyKlUqW52"
   },
   "source": [
    "# Question 4 (20 pts)\n",
    "Create a new monte carlo simulation that calculates the probability that the casino loses money based on the number of times that a player plays roulette.  Create a function p_casino_loss that takes as an argument the number of times that the player plays roulette (n_plays), and returns the probability that the casino loses money.  Your code should simulate spinning the roulette wheel.  Run the n_plays simulation a fixed large number of times (100 works) and return the average probability result.  Using data collected from p_casino_loss, produce a line plot that shows the probability that the casino loses money vs. the number of games played for number of games between 25 and 1000.  Describe what the results of the simulation show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZGCktkiqW52"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3G_bSWLqW52"
   },
   "source": [
    "Your explanation here:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_gi9RoUqW53"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tHtwU4EqW53"
   },
   "source": [
    "# Question 5 (10 pts)\n",
    "Compute the following matrix dot product manually by creating 2 dimensinal nympy arrays for each matrix, computing the matrix multiply using python for loops, and loading a new 2 dimensional numpy array with the answer.  Print the resulting numpy array.\n",
    "\n",
    "$$\n",
    "\\quad\n",
    "\\begin{bmatrix} \n",
    "3 & 7 \\\\\n",
    "6 & 9 \\\\\n",
    "4 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "*\n",
    "\\quad\n",
    "\\begin{bmatrix} \n",
    "2 & 5 & 7\\\\\n",
    "2 & 5 & 1\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52NV7tupqW53"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yz3ZnQK4qW53"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEJBdNH0qW53"
   },
   "source": [
    "# Question 6 (10 pts)\n",
    "Read each of the 4 assignment csv files into pandas dataframes named population_df, morttality_df, life_exp_df, and fertility_df.  Rename the column with the country names as \"Country\" in each of the dataframes.  Hint - the bash datafiles data_file_array at the start of the assignment has the file names you need to load.  Another thing you can do is click the colab file icon to the left to view the file names stored on the local colab instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2V11SDSdqW53"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVblZDMuqW54"
   },
   "outputs": [],
   "source": [
    "# grading cell - do not modify\n",
    "display(population_df.head())\n",
    "display(morttality_df.head())\n",
    "display(life_exp_df.head())\n",
    "display(fertility_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QciK5ZlNqW54"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVpHsOddqW54"
   },
   "source": [
    "# Question 7 (10 pts)\n",
    "The data frames from the question above are organized such that rows are countries and columns are years.  Reorganize each data frame such that each row contains 3 columns: country, year, and a data value.  This is known as the long or tidy format.  For example, the population data frame columns start out as country, year, year, year, ..., year.  After reorganizing, the population data frame columns will contain only 3 columns: country, year, and population.  Save the reorganized data into new data frames named tidy_population_df, tidy_morttality_df, tidy_life_exp_df, and tidy_fertility_df.  You are free to use any means necessary to perform this task but the pandas melt function may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8W_cdB-8qW54"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4QCXBnqqW54"
   },
   "outputs": [],
   "source": [
    "# grading cell - do not modify\n",
    "display(tidy_population_df.head())\n",
    "print(tidy_population_df.size)\n",
    "display(tidy_morttality_df.head())\n",
    "print(tidy_morttality_df.size)\n",
    "display(tidy_life_exp_df.head())\n",
    "print(tidy_life_exp_df.size)\n",
    "display(tidy_fertility_df.head())\n",
    "print(tidy_fertility_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klofkfXKqW54"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGtr9m_zqW55"
   },
   "source": [
    "# Question 8 (10 pts)\n",
    "Join all 4 dataframes together such that the country, year, population, mortality, life expectancy, and fertility columns are collected together in the same dataframe.  The join operation should not throw away any data.  Name the new dataframe concat_df.  Next, delete all rows where life expectancy and fertility are NAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqabX9mdqW55"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZfnbGzuqW55"
   },
   "outputs": [],
   "source": [
    "# grading cell - do not modify\n",
    "display(concat_df.head())\n",
    "print(concat_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5oTt2kuqW55"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg44WS-1qW55"
   },
   "source": [
    "# Question 9 (10 pts)\n",
    "Using concat_df, report the child mortality rate and life expectancy in 2015 for these 5 countries:\n",
    "1. Sri Lanka\n",
    "2. Poland\n",
    "3. Malaysia\n",
    "4. Pakistan\n",
    "5. Thailand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DshNgEKdqW55"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ur5aVUElqW56"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "IST-718 Spring 2022 Homework 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
