{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNfPaiAQsgBf"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmrHfEEjfShT"
   },
   "source": [
    "# Question 0 (-2 If not answered)\n",
    "Please provide the following the data so we can verify your github information and ensure accurate grading:\n",
    "- Your Name: Yunhan Zhang\n",
    "- Your SU ID: 405379315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svGJOJtifShH"
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professors: \n",
    "  - Willard Williamson <wewillia@syr.edu>\n",
    "  - Emory Creel <emcreel@g.syr.edu>\n",
    "- Faculty Assistants: \n",
    "  - Warren Justin Fernandes <wjfernan@syr.edu>\n",
    "  - Ruchita Hiteshkumar Harsora <\trharsora@g.syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n",
    "- Google Colab is the official class runtime environment so you should test your code on Colab before submission.\n",
    "- Do not modify cells marked as grading cells or marked as do not modify.\n",
    "- Before submitting your work, remember to check for run time errors with the following procedure:\n",
    "`Runtime `$\\rightarrow$ Factory reset runtime followed by Runtime $\\rightarrow$ Run All.  All runtime errors will result in a minimum penalty of half off.\n",
    "- All plots shall include descriptive title and axis labels.  Plot legends shall be included where possible.  Unless stated otherwise, plots can be made using any Python plotting package.\n",
    "- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n",
    "- Don't add or remove files from your git repo.\n",
    "- Do not change file names in your repo.  This also means don't change the title of the ipython notebook.\n",
    "- You are free to add additional code cells around the cells marked `your code here`.\n",
    "- import * is not allowed because it is considered a very bad coding practice and in some cases can result in a significant delay (which slows down the grading process) in loading imports.  For example, the statement `from sympy import *` is not allowed.  You must import the specific packages that you need. \n",
    "- The graders reserve the right to deduct points for subjective things we see with your code.  For example, if we ask you to create a pandas data frame to display values from an investigation and you hard code the values, we will take points off for that.  This is only one of many different things we could find in reviewing your code.  In general, write your code like you are submitting it for a code peer review in industry.  \n",
    "- Level of effort is part of our subjective grading.  For example, in cases where we ask for a more open ended investigation, some students put in significant effort and some students do the minimum possible to meet requirements.  In these cases, we may take points off for students who did not put in much effort as compared to students who put in a lot of effort.  We feel that the students who did a better job deserve a better grade.  We reserve the right to invoke level of effort grading at any time.\n",
    "- Your notebook must run from start to finish without requiring manual input by the graders.  For example, do not mount your personal Google drive in your notebook as this will require graders to perform manual steps.  In short, your notebook should run from start to finish with no runtime errors and no need for graders to perform any manual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BevKDzftfrm-"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Do not change or modify this cell\n",
    "# Need to install pyspark\n",
    "# if pyspark is already installed, will print a message indicating pyspark already installed\n",
    "pip install pyspark >& /dev/null \n",
    "\n",
    "# Download the data files from github\n",
    "# If the data file does not exist in the colab environment\n",
    "data_file_1=US_Airline_Tweets.csv\n",
    "\n",
    "if [[ ! -f ./${data_file_1} ]]; then \n",
    "   # download the data file from github and save it in this colab environment instance\n",
    "   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/${data_file_1} >& /dev/null \n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import random\n",
    "import requests\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import types\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVxonwEusgBt"
   },
   "source": [
    "# Sentiment Analysis\n",
    "In this assignment, you will use a twitter US airline dataset to perform sentiment analysis.  Specifically, you will use twitter data to predict the sentiment of tweets related to peoples experience with an airline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1tYn9Sc_v6-C"
   },
   "outputs": [],
   "source": [
    "# Grading cell\n",
    "# The purpose of the following boolean is to enable or disable grid search (see question 6a).  \n",
    "# During grading we want to turn grid search off.  \n",
    "# You should test your code with grid search set to False before submitting.\n",
    "# Your notebook should run in its entirety without crashing when enable_grid is\n",
    "# set to False before submitting.\n",
    "enable_grid = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZzjDc-QN6E8"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlXXgoe3sgBu"
   },
   "source": [
    "# Qustion 1: (10 pts)\n",
    "Read US_Airline_Tweets.csv into a spark dataframe named `tweets_df`.  Drop all columns except airline_sentiment, airline, and text.  Drop rows in which the airline_sentiment column is labeled with a neutral sentiment.  Drop rows which contain NA / Null values in any column. Transform the airline_sentiment column such that a negative sentiment is equal to 0 and a positive sentiment is equal to 1.  This dataset has a lot more negative than positive tweets.  Balance the dataset such that the percentage of negative and positive tweets is roughly 50% each.  Your solution must **randomly sample** the dataset **without replacement** to perform balancing.  Determine and print the resulting percentage of positive and negative tweets in the dataframe such that it's easy for the graders to find and interpret your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8Wl62qN9sgBu"
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "tweets_df_old = spark.read.csv('US_Airline_Tweets.csv', header=True)\n",
    "tweets_df_withna = tweets_df_old.drop(\"tweet_id\",\"airline_sentiment_confidence\",\"negativereason\",\"negativereason_confidence\",\n",
    "              \"airline_sentiment_gold\",\"name\",\"negativereason_gold\",\"retweet_count\",\"tweet_coord\",\n",
    "              \"tweet_created\",\"tweet_location\",\"user_timezone\")\n",
    "tweets_df_neutral = tweets_df_withna.where(tweets_df_withna.airline_sentiment!=\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA / Null values\n",
    "tweets_df_nona = tweets_df_neutral.na.drop('any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to 0 & 1\n",
    "tweets_df_nona_1 = tweets_df_nona.withColumn('airline_sentiment', regexp_replace('airline_sentiment', 'positive', '1'))\n",
    "tweets_df_unbalance = tweets_df_nona_1.withColumn('airline_sentiment', regexp_replace('airline_sentiment', 'negative', '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the dataset\n",
    "tweets_df = tweets_df_unbalance.sampleBy('airline_sentiment',{'0':0.22,'1':0.86},12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4964625518419127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of positive tweets\n",
    "tweets_df.where(tweets_df.airline_sentiment == '1').count() / 4099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4989021712612832"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of negative tweets\n",
    "tweets_df.where(tweets_df.airline_sentiment == '0').count() / 4099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2G8lflJ6sgBv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment         airline  \\\n",
       "0                 1  Virgin America   \n",
       "1                 0  Virgin America   \n",
       "2                 1  Virgin America   \n",
       "3                 1  Virgin America   \n",
       "4                 1  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0  @VirginAmerica plus you've added commercials t...  \n",
       "1  @VirginAmerica seriously would pay $30 a fligh...  \n",
       "2  @VirginAmerica yes, nearly every time I fly VX...  \n",
       "3    @virginamerica Well, I didn't…but NOW I DO! :-D  \n",
       "4  @VirginAmerica it was amazing, and arrived an ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4080, 3)\n"
     ]
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "tweets_pd = tweets_df.toPandas()\n",
    "display(tweets_pd.head())\n",
    "print(tweets_pd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8SRU7ZPsgBw"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmTNjNPtsgBw"
   },
   "source": [
    "# Question 2: (10 pts)\n",
    "Pre-process the data by creating a pipeline named `tweets_pre_proc_pipe`. Your pipeline should tokenize, remove stop words, and do a TF-IDF transformation.  Fit and execute your pipeline, and create a new dataframe named `tweets_pre_proc_df`.  Print the shape of the resulting TF-IDF data such that it's easy for the graders to find and understand as num rows x num words. Based on the shape of the TF-IDF data, would you expect a logistic regression model to overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer().setGaps(False)\\\n",
    "  .setPattern(\"\\\\p{L}+\")\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[airline_sentiment: string, airline: string, text: string, words: array<string>]\n"
     ]
    }
   ],
   "source": [
    "review_words_df = tokenizer.transform(tweets_df)\n",
    "print(review_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+--------------------+--------------------+\n",
      "|airline_sentiment|       airline|                text|               words|\n",
      "+-----------------+--------------+--------------------+--------------------+\n",
      "|                1|Virgin America|@VirginAmerica pl...|[virginamerica, p...|\n",
      "|                0|Virgin America|@VirginAmerica se...|[virginamerica, s...|\n",
      "|                1|Virgin America|@VirginAmerica ye...|[virginamerica, y...|\n",
      "|                1|Virgin America|@virginamerica We...|[virginamerica, w...|\n",
      "|                1|Virgin America|@VirginAmerica it...|[virginamerica, i...|\n",
      "+-----------------+--------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_words_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aEb3xvK8sgBx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the stop words from a website\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered\")\\\n",
    "  .setOutputCol(\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pre_proc_pipe = Pipeline(stages=[cv_pipeline, idf]).fit(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pre_proc_df = tweets_pre_proc_pipe.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_pre_proc_df shape:  4080 7\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the resulting TF-IDF data\n",
    "print(\"tweets_pre_proc_df shape: \", tweets_pre_proc_df.count(), len(tweets_pre_proc_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sR-RcabSsgBy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|airline_sentiment|       airline|                text|               words|            filtered|                  tf|               tfidf|\n",
      "+-----------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                1|Virgin America|@VirginAmerica pl...|[virginamerica, p...|[virginamerica, p...|(1108,[19,39,77,4...|(1108,[19,39,77,4...|\n",
      "|                0|Virgin America|@VirginAmerica se...|[virginamerica, s...|[virginamerica, s...|(1108,[1,2,19,86,...|(1108,[1,2,19,86,...|\n",
      "|                1|Virgin America|@VirginAmerica ye...|[virginamerica, y...|[virginamerica, y...|(1108,[2,15,19,40...|(1108,[2,15,19,40...|\n",
      "|                1|Virgin America|@virginamerica We...|[virginamerica, w...|[virginamerica, d...|(1108,[2,19,86,89...|(1108,[2,19,86,89...|\n",
      "|                1|Virgin America|@VirginAmerica it...|[virginamerica, i...|[virginamerica, a...|(1108,[19,35,42,7...|(1108,[19,35,42,7...|\n",
      "|                1|Virgin America|@VirginAmerica Th...|[virginamerica, t...|[virginamerica, g...|(1108,[2,16,19,21...|(1108,[2,16,19,21...|\n",
      "|                1|Virgin America|@VirginAmerica @v...|[virginamerica, v...|[virginamerica, v...|(1108,[2,12,18,19...|(1108,[2,12,18,19...|\n",
      "|                1|Virgin America|@VirginAmerica Th...|[virginamerica, t...|[virginamerica, t...|(1108,[7,19],[1.0...|(1108,[7,19],[1.9...|\n",
      "|                1|Virgin America|@VirginAmerica So...|[virginamerica, s...|[virginamerica, e...|(1108,[1,16,19,39...|(1108,[1,16,19,39...|\n",
      "|                0|Virgin America|@VirginAmerica  I...|[virginamerica, i...|[virginamerica, f...|(1108,[2,17,19,74...|(1108,[2,17,19,74...|\n",
      "+-----------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "tweets_pre_proc_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>[virginamerica, plus, you, ve, added, commerci...</td>\n",
       "      <td>[virginamerica, plus, ve, added, commercials, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>[virginamerica, seriously, would, pay, a, flig...</td>\n",
       "      <td>[virginamerica, seriously, pay, flight, seats,...</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.543307911496826, 1.6873795861567809, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>[virginamerica, yes, nearly, every, time, i, f...</td>\n",
       "      <td>[virginamerica, yes, nearly, time, fly, vx, ea...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>[virginamerica, well, i, didn, t, but, now, i,...</td>\n",
       "      <td>[virginamerica, didn, t, d]</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>[virginamerica, it, was, amazing, and, arrived...</td>\n",
       "      <td>[virginamerica, amazing, arrived, hour, early,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>1</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir Flight 236 was great. Fantastic c...</td>\n",
       "      <td>[americanair, flight, was, great, fantastic, c...</td>\n",
       "      <td>[americanair, flight, great, fantastic, cabin,...</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.543307911496826, 1.6873795861567809, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir Flight 953 NYC-Buenos Aires has b...</td>\n",
       "      <td>[americanair, flight, nyc, buenos, aires, has,...</td>\n",
       "      <td>[americanair, flight, nyc, buenos, aires, dela...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.543307911496826, 0.0, 0.0, 1.672915165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>1</td>\n",
       "      <td>American</td>\n",
       "      <td>Thank you. “@AmericanAir: @jlhalldc Customer R...</td>\n",
       "      <td>[thank, you, americanair, jlhalldc, customer, ...</td>\n",
       "      <td>[thank, americanair, jlhalldc, customer, relat...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.6729151656652144, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>1</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir Thanks! He is.</td>\n",
       "      <td>[americanair, thanks, he, is]</td>\n",
       "      <td>[americanair, thanks]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.6729151656652144, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>1</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>[americanair, thank, you, we, got, on, a, diff...</td>\n",
       "      <td>[americanair, thank, got, different, flight, c...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.0, 1.543307911496826, 0.0, 0.0, 1.672915165...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4080 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline_sentiment         airline  \\\n",
       "0                    1  Virgin America   \n",
       "1                    0  Virgin America   \n",
       "2                    1  Virgin America   \n",
       "3                    1  Virgin America   \n",
       "4                    1  Virgin America   \n",
       "...                ...             ...   \n",
       "4075                 1        American   \n",
       "4076                 0        American   \n",
       "4077                 1        American   \n",
       "4078                 1        American   \n",
       "4079                 1        American   \n",
       "\n",
       "                                                   text  \\\n",
       "0     @VirginAmerica plus you've added commercials t...   \n",
       "1     @VirginAmerica seriously would pay $30 a fligh...   \n",
       "2     @VirginAmerica yes, nearly every time I fly VX...   \n",
       "3       @virginamerica Well, I didn't…but NOW I DO! :-D   \n",
       "4     @VirginAmerica it was amazing, and arrived an ...   \n",
       "...                                                 ...   \n",
       "4075  @AmericanAir Flight 236 was great. Fantastic c...   \n",
       "4076  @AmericanAir Flight 953 NYC-Buenos Aires has b...   \n",
       "4077  Thank you. “@AmericanAir: @jlhalldc Customer R...   \n",
       "4078                        @AmericanAir Thanks! He is.   \n",
       "4079  @AmericanAir thank you we got on a different f...   \n",
       "\n",
       "                                                  words  \\\n",
       "0     [virginamerica, plus, you, ve, added, commerci...   \n",
       "1     [virginamerica, seriously, would, pay, a, flig...   \n",
       "2     [virginamerica, yes, nearly, every, time, i, f...   \n",
       "3     [virginamerica, well, i, didn, t, but, now, i,...   \n",
       "4     [virginamerica, it, was, amazing, and, arrived...   \n",
       "...                                                 ...   \n",
       "4075  [americanair, flight, was, great, fantastic, c...   \n",
       "4076  [americanair, flight, nyc, buenos, aires, has,...   \n",
       "4077  [thank, you, americanair, jlhalldc, customer, ...   \n",
       "4078                      [americanair, thanks, he, is]   \n",
       "4079  [americanair, thank, you, we, got, on, a, diff...   \n",
       "\n",
       "                                               filtered  \\\n",
       "0     [virginamerica, plus, ve, added, commercials, ...   \n",
       "1     [virginamerica, seriously, pay, flight, seats,...   \n",
       "2     [virginamerica, yes, nearly, time, fly, vx, ea...   \n",
       "3                           [virginamerica, didn, t, d]   \n",
       "4     [virginamerica, amazing, arrived, hour, early,...   \n",
       "...                                                 ...   \n",
       "4075  [americanair, flight, great, fantastic, cabin,...   \n",
       "4076  [americanair, flight, nyc, buenos, aires, dela...   \n",
       "4077  [thank, americanair, jlhalldc, customer, relat...   \n",
       "4078                              [americanair, thanks]   \n",
       "4079  [americanair, thank, got, different, flight, c...   \n",
       "\n",
       "                                                     tf  \\\n",
       "0     (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     (0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "4075  (0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4076  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4077  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "4078  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "4079  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "\n",
       "                                                  tfidf  \n",
       "0     (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     (0.0, 1.543307911496826, 1.6873795861567809, 0...  \n",
       "2     (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  \n",
       "3     (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  \n",
       "4     (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "4075  (0.0, 1.543307911496826, 1.6873795861567809, 0...  \n",
       "4076  (0.0, 1.543307911496826, 0.0, 0.0, 1.672915165...  \n",
       "4077  (0.0, 0.0, 0.0, 0.0, 1.6729151656652144, 0.0, ...  \n",
       "4078  (0.0, 0.0, 0.0, 0.0, 1.6729151656652144, 0.0, ...  \n",
       "4079  (0.0, 1.543307911496826, 0.0, 0.0, 1.672915165...  \n",
       "\n",
       "[4080 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4080, 7)\n"
     ]
    }
   ],
   "source": [
    "# convert to Pandas df to get a better view of the df\n",
    "tweets_pre_proc_df_pd = tweets_pre_proc_df.toPandas()\n",
    "display(tweets_pre_proc_df_pd)\n",
    "print(tweets_pre_proc_df_pd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqOueDw9N8sO"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4BtpaqhsgB0"
   },
   "source": [
    "Based on the shape of the TF-IDF data, would you expect a logistic regression model to overfit?\n",
    "\n",
    "Your explanation here: I would expect a logistic regression model to overfit since we have more number of feaures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzSNnallsgB0"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HuWaSIgsgB1"
   },
   "source": [
    "# Question 3: (10 pts)\n",
    "Since IDF considers a word's frequency across all documents in a corpus, you can use IDF as a form of inference.  Examine the documentation for the spark ML object that you used to create TF-IDF scores and learn how to extract the IDF scores for words in the corpus.  The idf object in your pipeline has a `values` attribute and a `tolist()` method which can be used to extract IDF values.  Create a pandas dataframe containing the 5 most important IDF scores named `most_imp_idf`.  Create another pandas dataframe containing the 5 least important IDF scores named `least_imp_idf`.  Each dataframe shall have 2 columns named `word` and `idf_score`.  Explain in words your interpretation of what the IDF scores mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[virginamerica, plus, ve, added, commercials, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[virginamerica, seriously, pay, flight, seats,...</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.543307911496826, 1.6873795861567809, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[virginamerica, yes, nearly, time, fly, vx, ea...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[virginamerica, didn, t, d]</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[virginamerica, amazing, arrived, hour, early,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[virginamerica, great, deal, thinking, nd, tri...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[virginamerica, virginmedia, m, flying, fabulo...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[virginamerica, thanks]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.92890293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[virginamerica, excited, cross, country, fligh...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.543307911496826, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[virginamerica, flew, nyc, sfo, week, couldn, ...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filtered  \\\n",
       "0  [virginamerica, plus, ve, added, commercials, ...   \n",
       "1  [virginamerica, seriously, pay, flight, seats,...   \n",
       "2  [virginamerica, yes, nearly, time, fly, vx, ea...   \n",
       "3                        [virginamerica, didn, t, d]   \n",
       "4  [virginamerica, amazing, arrived, hour, early,...   \n",
       "5  [virginamerica, great, deal, thinking, nd, tri...   \n",
       "6  [virginamerica, virginmedia, m, flying, fabulo...   \n",
       "7                            [virginamerica, thanks]   \n",
       "8  [virginamerica, excited, cross, country, fligh...   \n",
       "9  [virginamerica, flew, nyc, sfo, week, couldn, ...   \n",
       "\n",
       "                                                  tf  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "8  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               tfidf  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 1.543307911496826, 1.6873795861567809, 0...  \n",
       "2  (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  \n",
       "6  (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.92890293...  \n",
       "8  (0.0, 1.543307911496826, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "9  (0.0, 0.0, 1.6873795861567809, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pre_proc_df.limit(10).toPandas().loc[:10, ['filtered','tf', 'tfidf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          idf_values|\n",
      "+--------------------+\n",
      "|[3.07235032034616...|\n",
      "|[1.54330791149682...|\n",
      "|[1.68737958615678...|\n",
      "|[1.68737958615678...|\n",
      "|[3.07235032034616...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_values_from_vector(vector):\n",
    "    return vector.values.tolist()\n",
    "\n",
    "extract_values_from_vector_udf = fn.udf(extract_values_from_vector, types.ArrayType(types.DoubleType()))\n",
    "\n",
    "idf_values_df = tweets_pre_proc_df.select(extract_values_from_vector_udf(tweets_pre_proc_df['tfidf']).alias('idf_values'))\n",
    "idf_values_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|          idf_values|           idf_max|\n",
      "+--------------------+------------------+\n",
      "|[3.07235032034616...|6.2346557937259695|\n",
      "|[1.54330791149682...| 5.541508613166024|\n",
      "|[1.68737958615678...| 6.368187186350492|\n",
      "|[1.68737958615678...| 4.271046067571255|\n",
      "|[3.07235032034616...| 5.318365061851814|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max\n",
    "find_max = fn.udf(lambda x: float(np.max(x)), types.DoubleType())\n",
    "idf_max_df = idf_values_df.withColumn(\"idf_max\", find_max(\"idf_values\"))\n",
    "idf_max_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------+\n",
      "|          idf_values|           idf_max|max_idx|\n",
      "+--------------------+------------------+-------+\n",
      "|[3.07235032034616...|6.2346557937259695|      4|\n",
      "|[1.54330791149682...| 5.541508613166024|      6|\n",
      "|[1.68737958615678...| 6.368187186350492|      7|\n",
      "|[1.68737958615678...| 4.271046067571255|      3|\n",
      "|[3.07235032034616...| 5.318365061851814|      5|\n",
      "+--------------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_max_index = fn.udf( lambda x: int(np.argmax(x)))\n",
    "idf_maxidx_df = idf_max_df.withColumn(\"max_idx\",find_max_index(\"idf_values\"))\n",
    "idf_maxidx_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = tweets_pre_proc_pipe.stages[0].stages[-1].vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_values</th>\n",
       "      <th>idf_max</th>\n",
       "      <th>max_idx</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.072350320346163, 3.631966108281586, 4.15521...</td>\n",
       "      <td>6.234656</td>\n",
       "      <td>4</td>\n",
       "      <td>americanair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.543307911496826, 1.6873795861567809, 3.0723...</td>\n",
       "      <td>5.541509</td>\n",
       "      <td>6</td>\n",
       "      <td>jetblue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.6873795861567809, 2.9434593072781428, 3.072...</td>\n",
       "      <td>6.368187</td>\n",
       "      <td>7</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.6873795861567809, 3.072350320346163, 4.2032...</td>\n",
       "      <td>4.271046</td>\n",
       "      <td>3</td>\n",
       "      <td>southwestair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3.072350320346163, 3.5867095166934653, 3.6697...</td>\n",
       "      <td>5.318365</td>\n",
       "      <td>5</td>\n",
       "      <td>usairways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>[1.543307911496826, 1.6873795861567809, 1.6729...</td>\n",
       "      <td>6.234656</td>\n",
       "      <td>10</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>[1.543307911496826, 1.6729151656652144, 3.9073...</td>\n",
       "      <td>10.190443</td>\n",
       "      <td>5</td>\n",
       "      <td>usairways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>[1.6729151656652144, 2.3201359080992368, 2.837...</td>\n",
       "      <td>6.522338</td>\n",
       "      <td>4</td>\n",
       "      <td>americanair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>[1.6729151656652144, 1.9289029364080803]</td>\n",
       "      <td>1.928903</td>\n",
       "      <td>1</td>\n",
       "      <td>flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>[1.543307911496826, 1.6729151656652144, 2.3201...</td>\n",
       "      <td>5.423726</td>\n",
       "      <td>5</td>\n",
       "      <td>usairways</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4080 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             idf_values    idf_max max_idx  \\\n",
       "0     [3.072350320346163, 3.631966108281586, 4.15521...   6.234656       4   \n",
       "1     [1.543307911496826, 1.6873795861567809, 3.0723...   5.541509       6   \n",
       "2     [1.6873795861567809, 2.9434593072781428, 3.072...   6.368187       7   \n",
       "3     [1.6873795861567809, 3.072350320346163, 4.2032...   4.271046       3   \n",
       "4     [3.072350320346163, 3.5867095166934653, 3.6697...   5.318365       5   \n",
       "...                                                 ...        ...     ...   \n",
       "4075  [1.543307911496826, 1.6873795861567809, 1.6729...   6.234656      10   \n",
       "4076  [1.543307911496826, 1.6729151656652144, 3.9073...  10.190443       5   \n",
       "4077  [1.6729151656652144, 2.3201359080992368, 2.837...   6.522338       4   \n",
       "4078           [1.6729151656652144, 1.9289029364080803]   1.928903       1   \n",
       "4079  [1.543307911496826, 1.6729151656652144, 2.3201...   5.423726       5   \n",
       "\n",
       "              word  \n",
       "0      americanair  \n",
       "1          jetblue  \n",
       "2           thanks  \n",
       "3     southwestair  \n",
       "4        usairways  \n",
       "...            ...  \n",
       "4075       service  \n",
       "4076     usairways  \n",
       "4077   americanair  \n",
       "4078        flight  \n",
       "4079     usairways  \n",
       "\n",
       "[4080 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx_list=idf_maxidx_df.rdd.map(lambda x: x.max_idx).collect()\n",
    "max_idx_list = list(map(int, max_idx_list))\n",
    "\n",
    "most_imp_idf = idf_maxidx_df.withColumn(\"word\", fn.lit('na').cast(types.StringType()))\n",
    "most_imp_idf_pd = most_imp_idf.toPandas()\n",
    "\n",
    "count = most_imp_idf.count()\n",
    "for i in range(count):\n",
    "    most_imp_idf_pd.at[i, 'word'] = vocabulary[max_idx_list[i]]\n",
    "most_imp_idf_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_imp_idf \n",
    "most_imp_idf = most_imp_idf_pd.sort_values(by=['idf_max'], ascending=False).head(5)\n",
    "most_imp_idf.drop(['idf_values', 'max_idx'],axis=1,inplace=True)\n",
    "most_imp_idf.rename(columns = {'idf_max':'idf_score'}, inplace = True)\n",
    "# display(most_imp_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|          idf_values|           idf_min|\n",
      "+--------------------+------------------+\n",
      "|[3.07235032034616...| 3.072350320346163|\n",
      "|[1.54330791149682...| 1.543307911496826|\n",
      "|[1.68737958615678...|1.6873795861567809|\n",
      "|[1.68737958615678...|1.6873795861567809|\n",
      "|[3.07235032034616...| 3.072350320346163|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min\n",
    "find_min = fn.udf(lambda x: float(np.min(x)), types.DoubleType())\n",
    "idf_min_df = idf_values_df.withColumn(\"idf_min\", find_min(\"idf_values\"))\n",
    "idf_min_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------+\n",
      "|          idf_values|           idf_min|min_idx|\n",
      "+--------------------+------------------+-------+\n",
      "|[3.07235032034616...| 3.072350320346163|      0|\n",
      "|[1.54330791149682...| 1.543307911496826|      0|\n",
      "|[1.68737958615678...|1.6873795861567809|      0|\n",
      "|[1.68737958615678...|1.6873795861567809|      0|\n",
      "|[3.07235032034616...| 3.072350320346163|      0|\n",
      "+--------------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_min_index = fn.udf( lambda x: int(np.argmin(x)))\n",
    "idf_minidx_df = idf_min_df.withColumn(\"min_idx\",find_min_index(\"idf_values\"))\n",
    "idf_minidx_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_values</th>\n",
       "      <th>idf_min</th>\n",
       "      <th>min_idx</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.072350320346163, 3.631966108281586, 4.15521...</td>\n",
       "      <td>3.072350</td>\n",
       "      <td>0</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.543307911496826, 1.6873795861567809, 3.0723...</td>\n",
       "      <td>1.543308</td>\n",
       "      <td>0</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.6873795861567809, 2.9434593072781428, 3.072...</td>\n",
       "      <td>1.687380</td>\n",
       "      <td>0</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.6873795861567809, 3.072350320346163, 4.2032...</td>\n",
       "      <td>1.687380</td>\n",
       "      <td>0</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3.072350320346163, 3.5867095166934653, 3.6697...</td>\n",
       "      <td>3.072350</td>\n",
       "      <td>0</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          idf_values   idf_min min_idx    word\n",
       "0  [3.072350320346163, 3.631966108281586, 4.15521...  3.072350       0  united\n",
       "1  [1.543307911496826, 1.6873795861567809, 3.0723...  1.543308       0  united\n",
       "2  [1.6873795861567809, 2.9434593072781428, 3.072...  1.687380       0  united\n",
       "3  [1.6873795861567809, 3.072350320346163, 4.2032...  1.687380       0  united\n",
       "4  [3.072350320346163, 3.5867095166934653, 3.6697...  3.072350       0  united"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_idx_list = idf_minidx_df.rdd.map(lambda x: x.min_idx).collect()\n",
    "min_idx_list = list(map(int, min_idx_list))\n",
    "\n",
    "least_imp_idf = idf_minidx_df.withColumn(\"word\", fn.lit('na').cast(types.StringType()))\n",
    "least_imp_idf_pd = least_imp_idf.toPandas()\n",
    "\n",
    "count = least_imp_idf.count()\n",
    "for i in range(count):\n",
    "    least_imp_idf_pd.at[i, 'word'] = vocabulary[min_idx_list[i]]\n",
    "least_imp_idf_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least_imp_idf\n",
    "least_imp_idf = least_imp_idf_pd.sort_values(by=['idf_min'], ascending=True).head(5)\n",
    "least_imp_idf.drop(['idf_values', 'min_idx'],axis=1,inplace=True)\n",
    "least_imp_idf.rename(columns = {'idf_min':'idf_score'}, inplace = True)\n",
    "# display(least_imp_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uumED0kYsgB2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_score</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>27.707543</td>\n",
       "      <td>americanair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>19.787206</td>\n",
       "      <td>jetblue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>19.567014</td>\n",
       "      <td>usairways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>19.104562</td>\n",
       "      <td>southwestair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>18.350618</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idf_score          word\n",
       "1082  27.707543   americanair\n",
       "2723  19.787206       jetblue\n",
       "3558  19.567014     usairways\n",
       "1807  19.104562  southwestair\n",
       "3303  18.350618        thanks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_score</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1.383603</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>1.383603</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1.383603</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1.383603</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1.383603</td>\n",
       "      <td>united</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idf_score    word\n",
       "690   1.383603  united\n",
       "744   1.383603  united\n",
       "745   1.383603  united\n",
       "746   1.383603  united\n",
       "747   1.383603  united"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "display(most_imp_idf)\n",
    "display(least_imp_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPzl6yqmK2-s"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwZgc3jGsgB2"
   },
   "source": [
    "Your explanation here: TF-IDF has two layers of meanings, one is Term Frequency and the other is Inverse Document Frequency. The main idea of IDF is that if the fewer documents containing term T or the smaller N, the larger the value of IDF, it means that term T has good category differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNa3LZeYsgB2"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH7N8VBzsgB2"
   },
   "source": [
    "# Question 4: (10 pts)\n",
    "Create a new recursive pipeline named `lr_pipe` which encapsulates `tweets_pre_proc_pipe` and adds a logistic regression model and any needed logistic regression support objects.  Use default logistic regression hyper parameters.  Fit lr_pipe using `tweets_df`.  Score the model using ROC AUC.  Report the resulting AUC such that it is easy for graders to find and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.withColumn(\"airline_sentiment\",col(\"airline_sentiment\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airline_sentiment: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training, validation, and testing\n",
    "training_df, validation_df, testing_df = tweets_df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LFv-EWXNsgB3"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('airline_sentiment').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(stages=[tweets_pre_proc_pipe, lr]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurveMetrics(BinaryClassificationMetrics):\n",
    "    def __init__(self, *args):\n",
    "        super(CurveMetrics, self).__init__(*args)\n",
    "\n",
    "    def _to_list(self, rdd):\n",
    "        points = []\n",
    "        for row in rdd.collect():\n",
    "            points += [(float(row._1()), float(row._2()))]\n",
    "        return points\n",
    "\n",
    "    def get_curve(self, method):\n",
    "        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
    "        return self._to_list(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f99fc4d3310>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = lr_pipe.transform(validation_df)\n",
    "\n",
    "preds = predictions.select('airline_sentiment','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['airline_sentiment'])))\n",
    "points = CurveMetrics(preds).get_curve('roc')\n",
    "\n",
    "plt.figure()\n",
    "x_val = [x[0] for x in points]\n",
    "y_val = [x[1] for x in points]\n",
    "plt.title('Airline Sentiment Analysis ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.8138424821002387|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe.transform(validation_df).\\\n",
    "    select(fn.expr('float(prediction = airline_sentiment)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGU4OswusgB3"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTd-1FLSsgB3"
   },
   "source": [
    "# Question 5: (10 pts)\n",
    "Create 2 pandas dataframes named `lr_pipe_df_neg` and `lr_pipe_df_pos`which contain 2 colunms: `word` and `score`.  Load the 2 dataframes with the top 10 words and logistic regression coefficients that contribute the most to negative and positive sentiments respectively. Analyze the 2 dataframes and describe if the words make sense.  Do the words look like they are really negative and positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "JdBlW7IBsgB4"
   },
   "outputs": [],
   "source": [
    "vocabulary = tweets_pre_proc_pipe.stages[0].stages[-1].vocabulary\n",
    "score = lr_pipe.stages[-1].coefficients.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'score': score})\n",
    "lr_pipe_df_neg = coeffs_df.sort_values('score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_df_pos = coeffs_df.sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "v0Onlh5ksgB4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>afford</td>\n",
       "      <td>-37.876660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>hate</td>\n",
       "      <td>-29.551415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>knew</td>\n",
       "      <td>-27.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-23.438442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>failed</td>\n",
       "      <td>-23.084173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>screwed</td>\n",
       "      <td>-23.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>letting</td>\n",
       "      <td>-20.123741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>flyer</td>\n",
       "      <td>-19.295426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>value</td>\n",
       "      <td>-18.573790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>started</td>\n",
       "      <td>-18.563143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      score\n",
       "984     afford -37.876660\n",
       "414       hate -29.551415\n",
       "771       knew -27.650000\n",
       "229   terrible -23.438442\n",
       "812     failed -23.084173\n",
       "1010   screwed -23.002805\n",
       "625    letting -20.123741\n",
       "941      flyer -19.295426\n",
       "1001     value -18.573790\n",
       "804    started -18.563143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thanks</td>\n",
       "      <td>35.680330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thank</td>\n",
       "      <td>34.465426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>yay</td>\n",
       "      <td>26.346460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>reflight</td>\n",
       "      <td>23.748626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>impressed</td>\n",
       "      <td>22.510743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>comfortable</td>\n",
       "      <td>20.355753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>visit</td>\n",
       "      <td>20.337891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>resolution</td>\n",
       "      <td>20.065027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>great</td>\n",
       "      <td>20.007130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>thankful</td>\n",
       "      <td>19.758615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word      score\n",
       "7          thanks  35.680330\n",
       "8           thank  34.465426\n",
       "959           yay  26.346460\n",
       "425      reflight  23.748626\n",
       "488     impressed  22.510743\n",
       "823   comfortable  20.355753\n",
       "1022        visit  20.337891\n",
       "839    resolution  20.065027\n",
       "16          great  20.007130\n",
       "1056     thankful  19.758615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell - do not modify\n",
    "display(lr_pipe_df_neg)\n",
    "display(lr_pipe_df_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qV5rzFKLmjS"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdzhAZm7sgB4"
   },
   "source": [
    "Your explanation here: Words from both dataframes make sense. Most of the words are really positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebiGTaz_sgB5"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voK5KKVusgB5"
   },
   "source": [
    "# Question 6a: (5 pts)\n",
    "The goal of this question is to try to improve the score from question 4 using an elastic net regularization grid search on a new pipeline named `lr_pipe_1`. lr_pipe_1 is the same as lr_pipe above but we would like you to create a new pipe for grading purposes only.  I'm not sure if it's possible to increase the score or not.  You will be graded on level of effort to increase the score in relation to other students in the class.  All of your grid search code should be inside the `if enable_grid` statement in the cell below.  The enable_grid boolean is set to true in a grading cell above.  If any of the grid search code executes outside of the if statement, you will not get full credit for the question.  We want the ability to turn off the grid search during grading.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_par = 0.02\n",
    "alpha_par = 0.3\n",
    "lr_pipe = LogisticRegression().\\\n",
    "        setLabelCol('airline_sentiment').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(lambda_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(alpha_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_estimator = Pipeline(stages=[tokenizer, sw_filter, cv, idf, lr_pipe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_pipeline = lr_pipe_estimator.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|avg(float((prediction = airline_sentiment)))|\n",
      "+--------------------------------------------+\n",
      "|                          0.8719172633253779|\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_pipeline.transform(validation_df).select(fn.avg(fn.expr('float(prediction = airline_sentiment)'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "HLruVEZdsgB5"
   },
   "outputs": [],
   "source": [
    "# your grid search (and only your grid search) code here\n",
    "if enable_grid:\n",
    "    grid = ParamGridBuilder().\\\n",
    "    addGrid(lr_pipe.regParam, [0., 0.01, 0.02]).\\\n",
    "    addGrid(lr_pipe.elasticNetParam, [0., 0.2, 0.4]).\\\n",
    "    build()\n",
    "    all_models = []\n",
    "    \n",
    "    for j in range(len(grid)):\n",
    "        print(\"Fitting model {}\".format(j+1))\n",
    "        model = lr_pipe_estimator.fit(training_df, grid[j])\n",
    "        all_models.append(model)\n",
    "        \n",
    "    accuracies = [m.\\\n",
    "    transform(validation_df).\\\n",
    "    select(fn.avg(fn.expr('float(airline_sentiment = prediction)')).alias('accuracy')).\\\n",
    "    first().\\\n",
    "    accuracy for m in all_models]\n",
    "    \n",
    "    print(\"accuracies =\", accuracies)\n",
    "    \n",
    "    best_model_idx = np.argmax(accuracies)\n",
    "    print(\"best model index =\", best_model_idx)\n",
    "    print(\"best_grid =\", grid[best_model_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScGvacYlsgB5"
   },
   "source": [
    "##### Grading feedback cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IS9pI45ysgB5"
   },
   "source": [
    "# Question 6b (5 pts)\n",
    "Build a new pipeline named `lr_pipe_2` which uses the optimized model parameters from the grid search in question 6a above (the best model).  Create 2 variables named alpha and lambda and assign to them the best alpha and lambda produced by the grid search by hard coding the values. Fit and transform lr_pipe_2.  Compare AUC scores between lr_pipe_2 with lr_pipe in question 4.  Create a pandas dataframe named `comapre_1_df` which encapsulates the comparison data.  comapre_1_df Shall have 2 columns: `model_name` and `auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_par = 0.02\n",
    "alpha_par = 0.2\n",
    "lr_pipe_2 = LogisticRegression().\\\n",
    "        setLabelCol('airline_sentiment').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(lambda_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(alpha_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_2_estimator = Pipeline(stages=[tokenizer, sw_filter, cv, idf, lr_pipe_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_2_pipeline = lr_pipe_2_estimator.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          accuracy|\n",
      "+------------------+\n",
      "|0.8899755501222494|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_2_pipeline.transform(testing_df).select(fn.avg(fn.expr('float(prediction = airline_sentiment)')).alias('accuracy')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model_name': ['lr_pipe', 'lr_pipe_2'],\n",
    "        'auc_score': [0.8138424821002387, 0.8899755501222494]}\n",
    "comapre_1_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "VYZA46thsgB6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_pipe</td>\n",
       "      <td>0.813842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_pipe_2</td>\n",
       "      <td>0.889976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  auc_score\n",
       "0    lr_pipe   0.813842\n",
       "1  lr_pipe_2   0.889976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell - do not modify\n",
    "display(comapre_1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXdATaoUsgB6"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFs4wt5EsgB6"
   },
   "source": [
    "# Question 7 (10 pts)\n",
    "Perform inference on lr_pipe_2.  Write code to report how many words were eliminated from the best model in question 6b above (if any) as compared to the model in question 4 above.  Make sure your output is easy for the graders to find and interpret.\n",
    "\n",
    "Describe in words how feature selection is performed using elastic net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_pipeline.stages[2].vocabulary) - len(lr_pipe_2_pipeline.stages[2].vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gizxpUBRsgB7"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDF3MSNGMSut"
   },
   "source": [
    "Your explanation here: It picks a parameter ( 𝛼 ) deciding to consider L1 vs L2 regularization. If  𝛼=0 , then we choose L2, and if  𝛼=1  we choose L1. On the other hand, elastic net regularization comes with two additional parameters,  𝜆  and  𝛼 , and we must either select them a priori or use the validation set to choose the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq7sCMG9MT5v"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g8OEf4UsgB7"
   },
   "source": [
    "# Question 8 (10 pts)\n",
    "Perform the same inference analysis that you did in question 5 but name the data frames `lr_pipe_df_neg_1` and `lr_pipe_df_pos_1`.  Compare the word importance results with the results in question 5.  Do the most positive and most negative words produced by using regularization better reflect positive and negative sentiment than the most positive and negative words produced by the model that did not use regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "3x_hxUyMsgB7"
   },
   "outputs": [],
   "source": [
    "vocabulary_2 = lr_pipe_2_pipeline.stages[2].vocabulary\n",
    "score_2 = lr_pipe_2_pipeline.stages[-1].coefficients.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_df_2 = pd.DataFrame({'word': vocabulary_2, 'score': score_2})\n",
    "lr_pipe_df_neg_1 = coeffs_df_2.sort_values('score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_df_pos_1 = coeffs_df_2.sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "xdCz06VosgB7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.508733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hours</td>\n",
       "      <td>-0.464695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>option</td>\n",
       "      <td>-0.388146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hold</td>\n",
       "      <td>-0.367461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>years</td>\n",
       "      <td>-0.350957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>hate</td>\n",
       "      <td>-0.348468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>page</td>\n",
       "      <td>-0.345472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>hotel</td>\n",
       "      <td>-0.343112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>delayed</td>\n",
       "      <td>-0.337134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>sit</td>\n",
       "      <td>-0.333599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     score\n",
       "81     worst -0.508733\n",
       "22     hours -0.464695\n",
       "291   option -0.388146\n",
       "26      hold -0.367461\n",
       "683    years -0.350957\n",
       "552     hate -0.348468\n",
       "435     page -0.345472\n",
       "290    hotel -0.343112\n",
       "32   delayed -0.337134\n",
       "498      sit -0.333599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thank</td>\n",
       "      <td>1.039488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1.024871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>great</td>\n",
       "      <td>0.575626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>love</td>\n",
       "      <td>0.460406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>kudos</td>\n",
       "      <td>0.426258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>awesome</td>\n",
       "      <td>0.420622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>best</td>\n",
       "      <td>0.392631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>exceptional</td>\n",
       "      <td>0.380208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>good</td>\n",
       "      <td>0.378243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>thx</td>\n",
       "      <td>0.362234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word     score\n",
       "8          thank  1.039488\n",
       "7         thanks  1.024871\n",
       "15         great  0.575626\n",
       "25          love  0.460406\n",
       "252        kudos  0.426258\n",
       "49       awesome  0.420622\n",
       "54          best  0.392631\n",
       "580  exceptional  0.380208\n",
       "47          good  0.378243\n",
       "105          thx  0.362234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell - do not modify\n",
    "display(lr_pipe_df_neg_1)\n",
    "display(lr_pipe_df_pos_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzG2lc6ksgB7"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGjAkZENsgB8"
   },
   "source": [
    "Your explanation here: No, I don't think the most positive and most negative words produced by using regularization better reflect positive and negative sentiment than the most positive and negative words produced by the model that did not use regularization. Most of them make zero importance for predicting sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFrYfkWfsgB8"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhf2hfVUsgB8"
   },
   "source": [
    "# Question 9 (10 pts)\n",
    "Precision recall plots are very similar to receiver operating characteristic (ROC) curves.  The high level steps for creating a precision recall curve are the same as the steps needed to create a ROC curve as outlined in lecture. Learn about [precision recall curves](https://en.wikipedia.org/wiki/Precision_and_recall).  Create a precision recall plot for the best model in question 6.  Describe what axes are the same / different between the precision recall curve and the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "kys4SqgvsgB8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f99f7bccc40>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = lr_pipe_2_pipeline.transform(validation_df)\n",
    "\n",
    "preds = predictions.select('airline_sentiment','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['airline_sentiment'])))\n",
    "points = CurveMetrics(preds).get_curve('recallByThreshold')\n",
    "\n",
    "plt.figure()\n",
    "x_val = [x[0] for x in points]\n",
    "y_val = [x[1] for x in points]\n",
    "plt.title('PR Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUnE8Qb1Nxr3"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG7lJsd3sgB8"
   },
   "source": [
    "Your explanation here: The x-axis(Recall) in PR curve is the same as the y-axis(TPR) in ROC curve. The y-axis(Precision) is different from the x-axis in ROC curve. The Precision represents to TP/TP+FP. And the x-axis in ROC curve represents to FPR which = FP/FP+TN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atfg5seiNxEI"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gt76hKF8BRcW"
   },
   "source": [
    "# Question 10 (10 pts)\n",
    "Design and implement a method to rank the airlines in your dataset from best to worst.  Your solution can use model predictions or inference or both to perform this task. Implement your ranking algorithm in spark.  Create a spark dataframe named airline_rankings.  airline_rankings Shall have 3 columns: airline_name, num_reviews, and ranking.  Load the num_reviews column with the number of reviews associated with the airline.  Load the ranking column with your rank calculation result.  Sort airline rankings from best to worst (best at head, worst at tail).  \n",
    "\n",
    "Describe in words how your algorithm works in clear easy to understand language.  We will take points off for descriptions that are not clearly stated and easy to follow.  We don't expect to have to reverse engineer your code understand how your algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+--------------------+\n",
      "|airline_sentiment|       airline|                text|\n",
      "+-----------------+--------------+--------------------+\n",
      "|                1|Virgin America|@VirginAmerica pl...|\n",
      "|                0|Virgin America|@VirginAmerica se...|\n",
      "|                1|Virgin America|@VirginAmerica ye...|\n",
      "|                1|Virgin America|@virginamerica We...|\n",
      "|                1|Virgin America|@VirginAmerica it...|\n",
      "|                1|Virgin America|@VirginAmerica Th...|\n",
      "|                1|Virgin America|@VirginAmerica @v...|\n",
      "|                1|Virgin America|@VirginAmerica Th...|\n",
      "|                1|Virgin America|@VirginAmerica So...|\n",
      "|                0|Virgin America|@VirginAmerica  I...|\n",
      "|                1|Virgin America|I ❤️ flying @Virg...|\n",
      "|                1|Virgin America|@VirginAmerica yo...|\n",
      "|                0|Virgin America|@VirginAmerica wh...|\n",
      "|                1|Virgin America|@VirginAmerica I ...|\n",
      "|                1|Virgin America|@VirginAmerica I ...|\n",
      "|                0|Virgin America|@VirginAmerica am...|\n",
      "|                1|Virgin America|@VirginAmerica th...|\n",
      "|                1|Virgin America|@VirginAmerica @f...|\n",
      "|                0|Virgin America|@VirginAmerica Yo...|\n",
      "|                1|Virgin America|@VirginAmerica Vi...|\n",
      "+-----------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "B2th6hjcDEM6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+\n",
      "|       airline|                text|prediction|\n",
      "+--------------+--------------------+----------+\n",
      "|Virgin America|@VirginAmerica pl...|       1.0|\n",
      "|Virgin America|@VirginAmerica se...|       0.0|\n",
      "|Virgin America|@VirginAmerica ye...|       1.0|\n",
      "|Virgin America|@virginamerica We...|       1.0|\n",
      "|Virgin America|@VirginAmerica it...|       1.0|\n",
      "|Virgin America|@VirginAmerica Th...|       1.0|\n",
      "|Virgin America|@VirginAmerica @v...|       1.0|\n",
      "|Virgin America|@VirginAmerica Th...|       1.0|\n",
      "|Virgin America|@VirginAmerica So...|       1.0|\n",
      "|Virgin America|@VirginAmerica  I...|       0.0|\n",
      "|Virgin America|I ❤️ flying @Virg...|       1.0|\n",
      "|Virgin America|@VirginAmerica yo...|       1.0|\n",
      "|Virgin America|@VirginAmerica wh...|       0.0|\n",
      "|Virgin America|@VirginAmerica I ...|       1.0|\n",
      "|Virgin America|@VirginAmerica I ...|       1.0|\n",
      "|Virgin America|@VirginAmerica am...|       1.0|\n",
      "|Virgin America|@VirginAmerica th...|       1.0|\n",
      "|Virgin America|@VirginAmerica @f...|       1.0|\n",
      "|Virgin America|@VirginAmerica Yo...|       1.0|\n",
      "|Virgin America|@VirginAmerica Vi...|       1.0|\n",
      "+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_df = lr_pipe_2_pipeline.transform(tweets_df).select('airline', 'text', 'prediction')\n",
    "best_model_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|       airline|count(1)|\n",
      "+--------------+--------+\n",
      "|         Delta|     675|\n",
      "|Virgin America|     185|\n",
      "|        United|    1005|\n",
      "|    US Airways|     735|\n",
      "|     Southwest|     761|\n",
      "|      American|     719|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_df_count = best_model_df.groupby('airline').agg(fn.count('*'))\n",
    "best_model_df_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|       airline|sum(prediction)|\n",
      "+--------------+---------------+\n",
      "|         Delta|          499.0|\n",
      "|Virgin America|          139.0|\n",
      "|        United|          401.0|\n",
      "|    US Airways|          210.0|\n",
      "|     Southwest|          512.0|\n",
      "|      American|          278.0|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_df_sum = best_model_df.groupby('airline').sum()\n",
    "best_model_df_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-----+\n",
      "|  airline_name|num_reviews|  sum|\n",
      "+--------------+-----------+-----+\n",
      "|         Delta|        675|499.0|\n",
      "|Virgin America|        185|139.0|\n",
      "|        United|       1005|401.0|\n",
      "|    US Airways|        735|210.0|\n",
      "|     Southwest|        761|512.0|\n",
      "|      American|        719|278.0|\n",
      "+--------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_df_join = best_model_df_count.join(best_model_df_sum, \n",
    "                                              best_model_df_count.airline == best_model_df_sum.airline, \"inner\").select(best_model_df_count['airline'].alias('airline_name'), best_model_df_count['count(1)'].alias('num_reviews'), best_model_df_sum['sum(prediction)'].alias('sum'))\n",
    "best_model_df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+------------------+\n",
      "|  airline_name|num_reviews|              rate|\n",
      "+--------------+-----------+------------------+\n",
      "|         Delta|        675|0.7392592592592593|\n",
      "|Virgin America|        185|0.7513513513513513|\n",
      "|        United|       1005|0.3990049751243781|\n",
      "|    US Airways|        735|0.2857142857142857|\n",
      "|     Southwest|        761|0.6727989487516426|\n",
      "|      American|        719|0.3866481223922114|\n",
      "+--------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_df_join_rate = best_model_df_join.withColumn('rate', best_model_df_join['sum']/best_model_df_join['num_reviews'])\n",
    "best_model_df_join_rate_2 = best_model_df_join_rate.drop('sum')\n",
    "best_model_df_join_rate_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-------+\n",
      "|  airline_name|num_reviews|ranking|\n",
      "+--------------+-----------+-------+\n",
      "|Virgin America|        185|      1|\n",
      "|         Delta|        675|      2|\n",
      "|     Southwest|        761|      3|\n",
      "|        United|       1005|      4|\n",
      "|      American|        719|      5|\n",
      "|    US Airways|        735|      6|\n",
      "+--------------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "window = Window.orderBy(desc('rate'))\n",
    "airline_rankings = best_model_df_join_rate_2.withColumn('ranking', rank().over(window)).drop('rate')\n",
    "airline_rankings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjZOXElJNzhJ"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6PiT5FEDFpA"
   },
   "source": [
    "Your algorithm description here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "aWG1DI5mDeSg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_name</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>761</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>1005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American</td>\n",
       "      <td>719</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline_name  num_reviews  ranking\n",
       "0  Virgin America          185        1\n",
       "1           Delta          675        2\n",
       "2       Southwest          761        3\n",
       "3          United         1005        4\n",
       "4        American          719        5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_name</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>761</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>1005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American</td>\n",
       "      <td>719</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US Airways</td>\n",
       "      <td>735</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_name  num_reviews  ranking\n",
       "1        Delta          675        2\n",
       "2    Southwest          761        3\n",
       "3       United         1005        4\n",
       "4     American          719        5\n",
       "5   US Airways          735        6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "display(airline_rankings.toPandas().head())\n",
    "display(airline_rankings.toPandas().tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** I decide to use the best model (lr_pipe_2_pipeline) into the 'tweet_df' dataset and only select out 'airline', 'text', 'prediction' column since they are the most important ones. Then I count how many airlines are there and use this number to count how many reviews for each airline. And store them into a new column named \"num_reviews\" as requested. In order to get the 'ranking' outcome, I sum up all the 'prediction' values for each airline and divide by the 'num_reviews' and this rate can represent to the 'positive review rate' for each airline. Finally, I use rank() function to rank them from the most positive to lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntyK4q19N1wL"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj2KN5cawifc"
   },
   "source": [
    "# Question 11 (0 pts)\n",
    "Make sure to set enable_grid to False in the grading cell above and run the notebook in its entirety before submitting to verify that there are no runtime erros.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rUpGwM4N3w7"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
